model2path:
  llama2-7b-chat: "meta-llama/Llama-2-7b-chat-hf"
  # Add your fine-tuned model path here
  gsub-llama: "path/to/your/finetuned/model"

generator_model: "gsub-llama"
retrieval_method: "e5"
index_path: "path/to/index"
corpus_path: "path/to/corpus"

# Generation Config
max_new_tokens: 512
temperature: 0.0
top_p: 1.0
